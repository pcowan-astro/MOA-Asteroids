{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of how to instantiate, use, and retrain one of the custom classification models described in\n",
    "Towards Asteroid Detection in Microlensing Surveys with Deep Learning by Cowan et al.\n",
    "\n",
    "This notebook contains instructions to either:\n",
    "** load a saved classification model, complete with weights (available for all 5 classifiers) **\n",
    "or \n",
    "** load a model architecture from a class (MOA12, MOA14, and MOA15 only; the architectures for HybridA and Hybrid B are in their own notebook). Pretrained weights can then be loaded on to the models. **\n",
    "\n",
    "The instantiated models can then be used to make predictions or retrain either from scratch or with the pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "# An example of how to instantiate, use, and retrain one of the custom classification models described in\n",
    "# Towards Asteroid Detection in Microlensing Surveys with Deep Learning by Cowan et al.\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#import MOA15_Model # or MOA14_Model or MOA12_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "\n",
    "# Each data directory is expected to contain 2 directories: \n",
    "#  \"Yes\" containing tracklet images and \n",
    "#  \"No\" containing no-tracklet images\n",
    "\n",
    "TRAIN_DIR = r\"/path_to_training_set/\"\n",
    "VALID_DIR = r\"/path_to_validation_set/\"\n",
    "TEST_DIR = r\"/path_to_test_set/\"\n",
    "\n",
    "# Path to weights hdf5, if using\n",
    "WEIGHTS = r\"/path_to_weights/\"\n",
    "\n",
    "# Path to saved model h5 (contains weights), if using\n",
    "SAVED_MODEL = r\"/path_to_saved_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "image_size = 128  \n",
    "image_shape = (image_size,image_size,3)\n",
    "\n",
    "# Loading the data in a compatible format and standardizing values to lie between 0 & 1\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='binary')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    VALID_DIR,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='binary',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 12,197,249\n",
      "Trainable params: 12,189,761\n",
      "Non-trainable params: 7,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# If loading model architecture\n",
    "#moa15 = MOA15_Model.MOA15(image_shape)\n",
    "#moa15.model().summary()\n",
    "\n",
    "# If loading saved model\n",
    "moa15 = load_model(SAVED_MODEL)\n",
    "moa15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 7s 58ms/step - loss: 0.0849 - accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1829773336648941, 0.9723038077354431]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights (build and load_weights only needed if not working with saved model)\n",
    "#moa15.build(input_shape = (1, 128, 128, 3))\n",
    "#moa15.load_weights(WEIGHTS_DIR) \n",
    "\n",
    "# Compile model (required to make predictions)\n",
    "moa15.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Evaluate\n",
    "moa15.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------\n",
    "#To make predictions about image files in the given directory\n",
    "#-------------------------------------------------------------------\n",
    "def make_predictions(predict_dir):\n",
    "    count_predicted_tracklets = 0 #counter for number of files predicted to contain a tracklet\n",
    "    predicted_tracklets = [] #filenanes predicted to contain a tracklet\n",
    "\n",
    "    for fname in (glob.glob(predict_dir + \"*.jpg\")):\n",
    "        img_path = fname\n",
    "\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "        predictions = moa15.predict(img_array)\n",
    "\n",
    "        score = predictions[0]\n",
    "        if (score > 0.5):\n",
    "            count_predicted_tracklets += 1\n",
    "            predicted_tracklets.append(os.path.basename(fname))\n",
    "\n",
    "        print(\"%s is %.2f percent an mp and %.2f percent not an mp. Score is %.2f.\"\n",
    "            % (os.path.basename(img_path), 100 * score, 100 * (1 - score), score))\n",
    "    \n",
    "    return count_predicted_tracklets, predicted_tracklets\n",
    "\n",
    "# Usage\n",
    "predict_dir = r\"/path_to_files/\" \n",
    "count_predicted_tracklets, predicted_tracklets = make_predictions(predict_dir)\n",
    "print(f\"\\n{count_predicted_tracklets} tracklets found and they are in files:\")\n",
    "for fname in predicted_tracklets:\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------\n",
    "# To fine tune the model with more data\n",
    "#-------------------------------------------------------------------\n",
    "#default learning rate of 0.001 is far too big \n",
    "initial_learning_rate = 0.0001\n",
    "moa15.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=initial_learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#various callback can be used, particularly ModelCheckpoint and LearningRateScheduler\n",
    "history = moa15.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=valid_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
